{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#initialize environment, load modules/libraries\n",
    "\n",
    "import os\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import tensorflow_datasets as tfds\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "#import python code from seperate files\n",
    "from helpers.fourier_transform import load_wav, dft_logmag, patches, dft\n",
    "\n",
    "# load for test purposes\n",
    "from scipy.io import wavfile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "music_dir = './data/music_wav'\n",
    "\n",
    "# music data file names used for testing\n",
    "music_test = [\n",
    "    'unpoco.wav',\n",
    "    'blues.wav',\n",
    "    'gismonti.wav',\n",
    "    'ipanema.wav',\n",
    "    'deedee.wav',\n",
    "    'hendrix.wav',\n",
    "    'madradeus.wav',\n",
    "    'marlene.wav',\n",
    "    'beatles.wav',\n",
    "    'bagpipe.wav',\n",
    "    'redhot.wav',\n",
    "    'jazz.wav'\n",
    "]\n",
    "\n",
    "music_test = [os.path.join(music_dir, file) for file in music_test]\n",
    "\n",
    "music = [os.path.join(music_dir, file) for file in os.listdir(music_dir) if file.endswith('.wav')]\n",
    "\n",
    "# create set of audio files without test files\n",
    "music = list(set(music)-set(music_test))\n",
    "\n",
    "speech_dir = './data/speech_wav'\n",
    "\n",
    "# speech data file names used for testing\n",
    "speech_test = [\n",
    "    'comedy.wav',\n",
    "    'thlui.wav',\n",
    "    'voices.wav',\n",
    "    'conversion.wav',\n",
    "    'china.wav',\n",
    "    'vegetables2.wav',\n",
    "    'amal.wav',\n",
    "    'teachers2.wav',\n",
    "    'chant.wav',\n",
    "    'pulp2.wav',\n",
    "    'acomic.wav',\n",
    "    'kid.wav'\n",
    "]\n",
    "speech_test = [os.path.join(speech_dir, file) for file in speech_test]\n",
    "\n",
    "speech = [os.path.join(speech_dir, file) for file in os.listdir(speech_dir) if file.endswith('.wav')]\n",
    "\n",
    "# create set of audio files without test files\n",
    "speech = list(set(speech)-set(speech_test))\n",
    "\t  \n",
    "print(len(music), len(speech))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = speech_test + music_test\n",
    "test_labels = np.zeros(len(test))\n",
    "test_labels[0:len(speech_test)]=1\n",
    "\n",
    "split = len(speech)*8//10\n",
    "\n",
    "train = speech[:split] + music[:split]\n",
    "train_labels = np.zeros(len(train))\n",
    "train_labels[:split]=1\n",
    "\n",
    "validate = speech[split:] + music[split:]\n",
    "validate_labels = np.zeros(len(validate))\n",
    "validate_labels[:len(speech[split:])]=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_sounds = load_wav(test)\n",
    "train_sounds = load_wav(train)\n",
    "validate_sounds = load_wav(validate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(train_sounds[0])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fft_step=256\n",
    "fft_size=512\n",
    "fft_chunks = len(train_sounds[0])//fft_step\n",
    "\n",
    "test_logmag = dft_logmag(test_sounds,fft_chunks,fft_step,fft_size)\n",
    "train_logmag = dft_logmag(train_sounds,fft_chunks,fft_step,fft_size)\n",
    "validate_logmag = dft_logmag(validate_sounds,fft_chunks,fft_step,fft_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(train_logmag[0].T)\n",
    "plt.xlabel('t')\n",
    "plt.ylabel('frequency')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "patch_step = 32\n",
    "patch_size = 64\n",
    "\n",
    "def ds_window(sound, label, patch_step, patch_size):\n",
    "    labels = np.ones(len(sound))*label\n",
    "    sound = np.c_[sound,labels]\n",
    "    ds = tf.data.Dataset.from_tensor_slices(sound)\n",
    "    ds = ds.window(size=patch_size,shift=patch_step,drop_remainder=True)\n",
    "    ds = ds.flat_map(lambda x: x.batch(patch_size))\n",
    "    return ds\n",
    "\n",
    "def ds_patches(sounds, labels, patch_step, patch_size):\n",
    "    ds = ds_window(sounds[0],labels[0],patch_step,patch_size)\n",
    "    for sound, label in zip(sounds[1:],labels[1:]): ds = ds.concatenate(ds_window(sound,label,patch_step,patch_size))\n",
    "    ds = ds.map(lambda x: (x[:,:-1], x[0,-1]))\n",
    "    return ds\n",
    "\n",
    "test_ds = ds_patches(test_logmag, test_labels, patch_step, patch_size)\n",
    "train_ds = ds_patches(train_logmag, train_labels, patch_step, patch_size)\n",
    "validate_ds = ds_patches(validate_logmag, validate_labels, patch_step, patch_size)\n",
    "\n",
    "n_test = test_logmag.shape[0]*(((test_logmag.shape[1]-patch_size)//patch_step)+1)\n",
    "n_train = train_logmag.shape[0]*(((train_logmag.shape[1]-patch_size)//patch_step)+1)\n",
    "n_validate = validate_logmag.shape[0]*(((validate_logmag.shape[1]-patch_size)//patch_step)+1)\n",
    "\n",
    "print(f\"{n_test} samples for test.\")\n",
    "print(f\"{n_train} samples for training.\")\n",
    "print(f\"{n_validate} samples for validation.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n = 10\n",
    "for sound, label in train_ds.take(n):\n",
    "    sound = sound.numpy()\n",
    "    print(f\"{sound.shape} : {sound[[0,patch_step],0]} : {sound[[-patch_step-1,-1],0]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, (sound, label) in enumerate(train_ds.take(n)):\n",
    "    plt.subplot(1,n,i+1)\n",
    "    plt.imshow(sound.numpy().T)\n",
    "    if i == 0:\n",
    "        plt.xlabel('t')\n",
    "        plt.ylabel('frequency')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_ds = test_ds.shuffle(n_test)\n",
    "train_ds = train_ds.shuffle(n_train)\n",
    "validate_ds = validate_ds.shuffle(n_validate)\n",
    "\n",
    "test_x = test_ds.map(lambda x, y: x)\n",
    "test_y = test_ds.map(lambda x, y: y)\n",
    "\n",
    "train_x = train_ds.map(lambda x, y: x)\n",
    "train_y = train_ds.map(lambda x, y: y)\n",
    "\n",
    "validate_x = validate_ds.map(lambda x, y: x)\n",
    "validate_y = validate_ds.map(lambda x, y: y)\n",
    "\n",
    "print(f\"Samples are shuffled now ... {[int(label.numpy()) for label in test_y.take(20)]} ...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert the train and test datasets to NumPy arrays\n",
    "train_x_np = np.asarray(list(map(lambda x: x[0], tfds.as_numpy(train_ds))))\n",
    "train_y_np = np.asarray(list(map(lambda x: x[1], tfds.as_numpy(train_ds))))\n",
    "\n",
    "validate_x_np = np.asarray(list(map(lambda x: x[0], tfds.as_numpy(validate_ds))))\n",
    "validate_y_np = np.asarray(list(map(lambda x: x[1], tfds.as_numpy(validate_ds))))\n",
    "validate_y_np\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_19\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_64 (Conv2D)          (None, 62, 254, 32)       320       \n",
      "                                                                 \n",
      " max_pooling2d_56 (MaxPoolin  (None, 31, 127, 32)      0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " batch_normalization_70 (Bat  (None, 31, 127, 32)      128       \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " conv2d_65 (Conv2D)          (None, 29, 125, 64)       18496     \n",
      "                                                                 \n",
      " max_pooling2d_57 (MaxPoolin  (None, 14, 62, 64)       0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " batch_normalization_71 (Bat  (None, 14, 62, 64)       256       \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " conv2d_66 (Conv2D)          (None, 12, 60, 128)       73856     \n",
      "                                                                 \n",
      " max_pooling2d_58 (MaxPoolin  (None, 6, 30, 128)       0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " batch_normalization_72 (Bat  (None, 6, 30, 128)       512       \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " conv2d_67 (Conv2D)          (None, 4, 28, 256)        295168    \n",
      "                                                                 \n",
      " max_pooling2d_59 (MaxPoolin  (None, 2, 14, 256)       0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " batch_normalization_73 (Bat  (None, 2, 14, 256)       1024      \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " flatten_16 (Flatten)        (None, 7168)              0         \n",
      "                                                                 \n",
      " dense_32 (Dense)            (None, 512)               3670528   \n",
      "                                                                 \n",
      " batch_normalization_74 (Bat  (None, 512)              2048      \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " dense_33 (Dense)            (None, 1)                 513       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 4,062,849\n",
      "Trainable params: 4,060,865\n",
      "Non-trainable params: 1,984\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Define the input shape of the images\n",
    "input_shape = (64, 256, 1)\n",
    "\n",
    "# Define the model architecture\n",
    "model = tf.keras.Sequential([\n",
    "    \n",
    "    # First convolutional layer\n",
    "    tf.keras.layers.Conv2D(filters=32, kernel_size=(3, 3), activation='relu', input_shape=input_shape),\n",
    "    tf.keras.layers.MaxPooling2D(pool_size=(2, 2)),\n",
    "    tf.keras.layers.BatchNormalization(),\n",
    "    \n",
    "    # Second convolutional layer\n",
    "    tf.keras.layers.Conv2D(filters=64, kernel_size=(3, 3), activation='relu'),\n",
    "    tf.keras.layers.MaxPooling2D(pool_size=(2, 2)),\n",
    "    tf.keras.layers.BatchNormalization(),\n",
    "    \n",
    "    # Third convolutional layer\n",
    "    tf.keras.layers.Conv2D(filters=128, kernel_size=(3, 3), activation='relu'),\n",
    "    tf.keras.layers.MaxPooling2D(pool_size=(2, 2)),\n",
    "    tf.keras.layers.BatchNormalization(),\n",
    "    \n",
    "    # Fourth convolutional layer\n",
    "    tf.keras.layers.Conv2D(filters=256, kernel_size=(3, 3), activation='relu'),\n",
    "    tf.keras.layers.MaxPooling2D(pool_size=(2, 2)),\n",
    "    tf.keras.layers.BatchNormalization(),\n",
    "    \n",
    "    # Flatten the output of the convolutional layers\n",
    "    tf.keras.layers.Flatten(),\n",
    "    \n",
    "    # First fully connected layer\n",
    "    tf.keras.layers.Dense(units=512, activation='relu'),\n",
    "    tf.keras.layers.BatchNormalization(),\n",
    "    \n",
    "    # Second fully connected layer\n",
    "    tf.keras.layers.Dense(units=1, activation='sigmoid')\n",
    "])\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer=tf.keras.optimizers.Adam(),\n",
    "              loss=tf.keras.losses.BinaryCrossentropy(),\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "203/203 [==============================] - 58s 274ms/step - loss: 0.8118 - accuracy: 0.4981 - val_loss: 0.7271 - val_accuracy: 0.4983\n",
      "Epoch 2/5\n",
      "203/203 [==============================] - 56s 275ms/step - loss: 0.7218 - accuracy: 0.5168 - val_loss: 0.7193 - val_accuracy: 0.5144\n",
      "Epoch 3/5\n",
      "203/203 [==============================] - 67s 329ms/step - loss: 0.7059 - accuracy: 0.5421 - val_loss: 0.8448 - val_accuracy: 0.4879\n",
      "Epoch 4/5\n",
      "203/203 [==============================] - 59s 288ms/step - loss: 0.6885 - accuracy: 0.5591 - val_loss: 0.7116 - val_accuracy: 0.4730\n",
      "Epoch 5/5\n",
      "203/203 [==============================] - 60s 295ms/step - loss: 0.6688 - accuracy: 0.5874 - val_loss: 0.7178 - val_accuracy: 0.5000\n"
     ]
    }
   ],
   "source": [
    "save_path = '../save/mnist_{epoch}.ckpt'\n",
    "save_callback = tf.keras.callbacks.ModelCheckpoint(filepath=save_path, save_weights_only=True)\n",
    "\n",
    "hist = model.fit(x=train_x_np, y=train_y_np,\n",
    "          epochs=5, batch_size=32, \n",
    "          validation_data=(validate_x_np, validate_y_np))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_21\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_72 (Conv2D)          (None, 31, 127, 32)       320       \n",
      "                                                                 \n",
      " conv2d_73 (Conv2D)          (None, 15, 63, 64)        18496     \n",
      "                                                                 \n",
      " conv2d_74 (Conv2D)          (None, 7, 31, 128)        73856     \n",
      "                                                                 \n",
      " conv2d_75 (Conv2D)          (None, 3, 15, 256)        295168    \n",
      "                                                                 \n",
      " flatten_18 (Flatten)        (None, 11520)             0         \n",
      "                                                                 \n",
      " dense_36 (Dense)            (None, 512)               5898752   \n",
      "                                                                 \n",
      " dense_37 (Dense)            (None, 1)                 513       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 6,287,105\n",
      "Trainable params: 6,287,105\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Define the model architecture\n",
    "model2 = tf.keras.models.Sequential([\n",
    "    # First convolutional layer\n",
    "    tf.keras.layers.Conv2D(filters=32, kernel_size=3, strides=2, activation='relu', input_shape=input_shape),\n",
    "    # Second convolutional layer\n",
    "    tf.keras.layers.Conv2D(filters=64, kernel_size=3, strides=2, activation='relu'),\n",
    "    # Third convolutional layer\n",
    "    tf.keras.layers.Conv2D(filters=128, kernel_size=3, strides=2, activation='relu'),\n",
    "    # Fourth convolutional layer\n",
    "    tf.keras.layers.Conv2D(filters=256, kernel_size=3, strides=2, activation='relu'),\n",
    "    # Flatten the output of the convolutional layers\n",
    "    tf.keras.layers.Flatten(),\n",
    "    # First fully connected layer\n",
    "    tf.keras.layers.Dense(units=512, activation='relu'),\n",
    "    # Second fully connected layer (output layer)\n",
    "    tf.keras.layers.Dense(units=1, activation='sigmoid')\n",
    "])\n",
    "\n",
    "# Compile the model\n",
    "model2.compile(optimizer=tf.keras.optimizers.Adam(),\n",
    "              loss=tf.keras.losses.BinaryCrossentropy(),\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "model2.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "203/203 [==============================] - 24s 109ms/step - loss: 0.7213 - accuracy: 0.4972 - val_loss: 0.6932 - val_accuracy: 0.5000\n",
      "Epoch 2/5\n",
      "203/203 [==============================] - 21s 105ms/step - loss: 0.6932 - accuracy: 0.5000 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 3/5\n",
      "203/203 [==============================] - 21s 106ms/step - loss: 0.6932 - accuracy: 0.4983 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 4/5\n",
      "203/203 [==============================] - 21s 105ms/step - loss: 0.6948 - accuracy: 0.5088 - val_loss: 0.6932 - val_accuracy: 0.5000\n",
      "Epoch 5/5\n",
      "203/203 [==============================] - 21s 105ms/step - loss: 0.6934 - accuracy: 0.4929 - val_loss: 0.6931 - val_accuracy: 0.5000\n"
     ]
    }
   ],
   "source": [
    "save_path = '../save/mnist_{epoch}.ckpt'\n",
    "save_callback = tf.keras.callbacks.ModelCheckpoint(filepath=save_path, save_weights_only=True)\n",
    "\n",
    "hist = model2.fit(x=train_x_np, y=train_y_np,\n",
    "          epochs=5, batch_size=32, \n",
    "          validation_data=(validate_x_np, validate_y_np))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
